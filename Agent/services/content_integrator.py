#--- START OF FILE core/ai_content_integrator.py ---

# -*- coding: utf-8 -*-
"""
AIå†…å®¹é›†æˆå™¨ (æ€§èƒ½ä¼˜åŒ–ä¸é€»è¾‘å¢å¼ºå®Œæ•´ç‰ˆ)
åŠŸèƒ½ï¼šè´Ÿè´£ä½¿ç”¨AIæ¨¡å‹æ•´åˆæ—…æ¸¸è§„åˆ’æ•°æ®
ä¼˜åŒ–ï¼š
1. æ™ºèƒ½ç´ æè¿‡æ»¤ï¼šä»…åŒ¹é…è¡Œç¨‹ä¸­æ¶‰åŠçš„éé—é¡¹ç›®ï¼ŒPrompt é•¿åº¦å‡å°‘ 60%ã€‚
2. è¡Œç¨‹æ•°æ®ç˜¦èº«ï¼šç§»é™¤åæ ‡ç­‰ AI ç¼–å†™æ–‡æ¡ˆæ— éœ€çš„å­—æ®µã€‚
3. å†å²æ„å›¾èšç„¦ï¼šä¿ç•™æœ€è¿‘ 8 æ¡å¯¹è¯å†å²ï¼Œç¡®ä¿ç”¨æˆ·ä¿®æ”¹æŒ‡ä»¤è¢«ç²¾å‡†æ‰§è¡Œã€‚
"""

import json
import hashlib
from typing import Dict, List, Any, Optional
from datetime import datetime
from loguru import logger
from Agent.utils.content_extractor import ContentExtractor
from Agent.prompts import CONVERSATION_SUMMARY_PROMPT


class AIContentIntegrator:
    """
    AIå†…å®¹é›†æˆå™¨ï¼Œè´Ÿè´£ä½¿ç”¨AIæ¨¡å‹æ•´åˆæ—…æ¸¸è§„åˆ’æ•°æ®
    """
    
    def __init__(self, ali_model=None):
        """
        åˆå§‹åŒ–AIå†…å®¹é›†æˆå™¨
        
        Args:
            ali_model: é˜¿é‡Œäº‘AIæ¨¡å‹å®ä¾‹
        """
        self.ali_model = ali_model
        self._content_cache = {}  # å†…å®¹ç¼“å­˜
        self._cache_timeout = 300  # ç¼“å­˜è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self.content_extractor = ContentExtractor()
        logger.info("AIå†…å®¹é›†æˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def integrate_travel_plan_content(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ•´åˆæ—…æ¸¸è§„åˆ’å†…å®¹å…¥å£
        """
        try:
            logger.info("å¼€å§‹AIè‡ªä¸»æ•´åˆæ—…æ¸¸è§„åˆ’å†…å®¹")
            
            # å¤„ç†combined_dataç»“æ„
            actual_data = result.get('plan_data', result)
            
            # ä¼˜å…ˆä» result è·å– conversation_history (é€šå¸¸åœ¨ export æ¥å£ä¸­ä¼ å…¥)
            conversation_history = result.get('conversation_history', [])
            if not conversation_history:
                # å…¶æ¬¡ä» actual_data è·å–
                conversation_history = actual_data.get('conversation_history', [])
            
            # å¦‚æœæ²¡æœ‰AIæ¨¡å‹ï¼Œç›´æ¥è¿”å›å¤‡ç”¨å†…å®¹
            if not self.ali_model:
                logger.warning("æœªæä¾›AIæ¨¡å‹ï¼Œä½¿ç”¨åŸºç¡€æ•´åˆ")
                return self._create_fallback_content(actual_data)
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(result, conversation_history)
            cached_content = self._get_cached_content(cache_key)
            if cached_content:
                logger.info("ä½¿ç”¨ç¼“å­˜çš„AIæ•´åˆå†…å®¹")
                return cached_content
            
            # è®©AIè‡ªä¸»åˆ†æå’Œè§„åˆ’å†…å®¹ç»“æ„
            integrated_content = await self._ai_autonomous_content_integration(result, conversation_history)
            
            logger.info("AIè‡ªä¸»æ—…æ¸¸è§„åˆ’å†…å®¹æ•´åˆå®Œæˆ")
            
            # éªŒè¯ç”Ÿæˆçš„å†…å®¹
            if integrated_content.get('content_type') != 'rich_text' or not integrated_content.get('text_content'):
                logger.warning("AIç”Ÿæˆçš„å†…å®¹ä¸ç¬¦åˆé¢„æœŸï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                return self._create_fallback_content(result)
            
            # å­˜å…¥ç¼“å­˜
            self._content_cache[cache_key] = {
                'content': integrated_content,
                'timestamp': datetime.now().timestamp()
            }
            
            return integrated_content
            
        except Exception as e:
            logger.error(f"AIè‡ªä¸»æ•´åˆæ—…æ¸¸è§„åˆ’å†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return self._create_fallback_content(result.get('plan_data', result))
    
    def _generate_cache_key(self, result: Dict[str, Any], conversation_history: List[Dict] = None) -> str:
        """ç”Ÿæˆå†…å®¹ç¼“å­˜é”®"""
        plan_id = result.get('plan_id', 'unknown')
        # è·å–æœ€è¿‘ 3 æ¡å†å²å¹¶è½¬ä¸ºå­—ç¬¦ä¸²
        history_str = json.dumps(conversation_history[-3:] if conversation_history else [], ensure_ascii=False)
        
        # ã€ä¿®æ­£åçš„ä»£ç ã€‘
        content_hash = hashlib.md5(history_str.encode()).hexdigest()[:10]
        
        # è°ƒè¯•æœŸé—´ä¾ç„¶è¿”å›æ—¶é—´æˆ³ï¼Œç¡®ä¿æ¯æ¬¡è¯·æ±‚éƒ½è§¦å‘ AI ç”Ÿæˆ
        # å¦‚æœè¦å¯ç”¨ç¼“å­˜ï¼Œè¯·æ”¹ä¸ºè¿”å› f"{plan_id}_{content_hash}"
        return str(datetime.now().timestamp())
    
    def _is_cache_valid(self, cache_entry: Dict[str, Any]) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if not cache_entry:
            return False
        timestamp = cache_entry.get('timestamp', 0)
        return (datetime.now().timestamp() - timestamp) < self._cache_timeout
    
    def _get_cached_content(self, cache_key: str) -> Dict[str, Any]:
        """è·å–ç¼“å­˜å†…å®¹"""
        entry = self._content_cache.get(cache_key)
        if self._is_cache_valid(entry):
            return entry['content']
        return {}
    
    def _extract_actual_data(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """æå–å®é™…çš„æ•°æ®"""
        if 'plan_data' in result:
            return result['plan_data']
        return result
    
    def _format_recommendations(self, recommendations: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ç³»ç»Ÿç”Ÿæˆçš„å»ºè®®"""
        if not recommendations:
            return "æš‚æ— ç³»ç»Ÿå»ºè®®"
        
        lines = []
        if 'travel_tips' in recommendations and recommendations['travel_tips']:
            lines.append("ã€å®ç”¨è´´å£«ã€‘ï¼š")
            for tip in recommendations['travel_tips']:
                lines.append(f"- {tip}")
        
        if 'packing_list' in recommendations and recommendations['packing_list']:
            lines.append("\nã€æ‰“åŒ…æ¸…å•ã€‘ï¼š")
            for item in recommendations['packing_list']:
                lines.append(f"- {item}")
        
        if 'budget_estimate' in recommendations:
             lines.append("\nã€é¢„ç®—å»ºè®®ã€‘ï¼šè¯·æ ¹æ®å®é™…æƒ…å†µå‚è€ƒç³»ç»Ÿä¼°ç®—ã€‚")
             
        return "\n".join(lines)
    
    def _extract_conversation_history_list(self, result: Dict[str, Any]) -> List[Dict]:
        """æå–åˆ—è¡¨æ ¼å¼çš„å¯¹è¯å†å²"""
        if 'conversation_history' in result:
            return result['conversation_history']
        return []

    async def _ai_autonomous_content_integration(self, result: Dict[str, Any], conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """
        æ ¸å¿ƒæ‰‹æœ¯å¼ä¿®æ”¹ï¼šAIè‡ªä¸»æ•´åˆå†…å®¹
        """
        try:
            # 1. åŸºç¡€æ•°æ®æå–
            actual_data = self._extract_actual_data(result)
            destination = self.content_extractor.extract_destination(actual_data)
            travel_dates = self.content_extractor.extract_travel_dates(actual_data)
            travel_days = self.content_extractor.extract_travel_days(actual_data)
            weather_summary = self.content_extractor.format_weather_info(actual_data.get('weather_info', {}))
            sys_recs = self._format_recommendations(actual_data.get('recommendations', {}))
            start_location = actual_data.get('basic_info', {}).get('departure', 'æœªæŒ‡å®š')
            
            # 2. ã€æ™ºèƒ½æ‘˜è¦ï¼šå¯¹è¯å†å²å¤„ç†ã€‘ä½¿ç”¨ LLM æ™ºèƒ½æ‘˜è¦æå–å…³é”®ä¿¡æ¯
            formatted_history = await self._build_conversation_summary(conversation_history, actual_data)

            # 3. ã€æ€§èƒ½ä¼˜åŒ–ï¼šç´ æåº“ç²¾å‡†åŒ¹é…ã€‘åªæå–è¡Œç¨‹ä¸­å‡ºç°çš„éé—é¡¹ç›®æè¿°
            itinerary_raw = actual_data.get('itinerary', [])
            planned_item_names = set()
            for day in itinerary_raw:
                for item in day.get('items', []):
                    planned_item_names.add(item.get('name'))

            heritage_items = actual_data.get('heritage_items', [])
            if not heritage_items and 'heritage_overview' in actual_data:
                heritage_items = actual_data['heritage_overview'].get('heritage_items', [])
            
            heritage_context_list = []
            for item in heritage_items:
                name = item.get('name', 'æœªçŸ¥é¡¹ç›®')
                # ä»…å°†è¡Œç¨‹å•ä¸­æ¶‰åŠçš„é¡¹ç›®è¯¦æƒ…å‘ç»™ AIï¼Œæå¤§é™ä½ Prompt é•¿åº¦
                if name in planned_item_names:
                    desc = item.get('full_description') or item.get('description', 'æš‚æ— è¯¦ç»†ä»‹ç»')
                    heritage_context_list.append(f"- **{name}** ({item.get('region', '')}): {desc[:350]}...")
            
            heritage_context_str = "\n".join(heritage_context_list) or "è¯·åŸºäºç›®çš„åœ°é€šç”¨æ–‡åŒ–èƒŒæ™¯è¿›è¡Œæ‰©å†™ã€‚"
            
            # 4. ã€æ€§èƒ½ä¼˜åŒ–ï¼šè¡Œç¨‹éª¨æ¶è„±è„‚ã€‘ç§»é™¤åæ ‡ç­‰AIä¸éœ€è¦çš„å­—æ®µ
            slim_itinerary = []
            for day in itinerary_raw:
                day_slim = {
                    "day": day.get('day'),
                    "theme": day.get('theme'),
                    "items": [{"name": i.get('name'), "time": i.get('time', 'å¾…å®š')} for i in day.get('items', [])]
                }
                slim_itinerary.append(day_slim)
            slim_itinerary_json = json.dumps(slim_itinerary, ensure_ascii=False)

            # 5. æ„å»ºä¸“å®¶çº§å¢å¼º Prompt
            prompt = f"""
# Role Definition
ä½ æ˜¯ä¸€ä½æ·±è€•é™•è¥¿æ–‡åŒ–30å¹´çš„**èµ„æ·±è€ƒå¤å­¦å®¶**ä¸**é¡¶çº§å®šåˆ¶æ—…è¡Œç­–åˆ’å¸ˆ**ã€‚ä½ ä¸ä»…ç²¾é€šåœ°ç†äº¤é€šï¼Œæ›´èƒ½æ·±åº¦è§£è¯»ä¸‰ç§¦å¤§åœ°çš„éé—æ–‡åŒ–ç²¾é«“ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºç”¨æˆ·éœ€æ±‚ã€å®æ—¶å¤©æ°”åŠéé—ç´ æï¼Œæ’°å†™ä¸€ä»½å…·æœ‰**å²è¯—æ„Ÿã€äººæ–‡æƒ…æ€€ä¸”å…·å¤‡æé«˜æ‰§è¡ŒåŠ›**çš„æ·±åº¦æ—…è¡Œè®¡åˆ’ä¹¦ã€‚

# ğŸ“‹ Context & Constraints
- **ç›®çš„åœ°/å‡ºå‘åœ°**ï¼š{destination} / {start_location}
- **å¤©æ•°/æ—¥æœŸ**ï¼š{travel_days}å¤© / {travel_dates}
- **ğŸŒ¤ï¸ å¤©æ°”çº¦æŸï¼ˆæ ¸å¿ƒå› å­ï¼‰**ï¼š{weather_summary}
  *ã€æŒ‡ä»¤ã€‘ï¼šå¦‚æœå¤©æ°”åŒ…å«é›¨/é›ª/ææ¸©ï¼Œä½ å¿…é¡»åœ¨è¡Œç¨‹ä¸­ä¸»åŠ¨è°ƒæ•´æˆ·å¤–æ´»åŠ¨ï¼Œå¹¶åœ¨é”¦å›Šä¸­ç»™å‡ºé¢„æ¡ˆã€‚*

# ğŸš¨ INTELLIGENT MODIFICATION LOGIC (æœ€é«˜ä¼˜å…ˆçº§)
**ä½ å¿…é¡»æ ¹æ®ä»¥ä¸‹å¯¹è¯å†å²ï¼Œåœ¨â€œæ¯æ—¥æ·±åº¦è¡Œç¨‹â€çš„æ­£æ–‡ä¸­è½å®ç”¨æˆ·çš„ä¿®æ”¹æ„å›¾ï¼ˆå¦‚åŠ æ™¯ç‚¹ã€æ”¹åå¥½ç­‰ï¼‰ï¼**
--- ğŸ’¬ å¯¹è¯å†å²è®°å½• ---
{formatted_history}
--- ç»“æŸ ---

# ğŸ—ºï¸ ç˜¦èº«è¡Œç¨‹éª¨æ¶ (è¯·åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œé‡æ„ä¸æ‰©å†™)
{slim_itinerary_json}

# ğŸ“š å…³è”éé—ç´ æåº“
{heritage_context_str}

# ğŸ’¡ ç³»ç»Ÿå»ºè®®æ•´åˆ
{sys_recs}

# Output Requirements
è¯·æ’°å†™ä¸€ä»½ Markdown æ ¼å¼çš„æ·±åº¦è·¯ä¹¦ï¼Œè¦æ±‚å†…å®¹ä¸°å¯Œã€‚
1.  **å®šåˆ¶è¯´æ˜**ï¼šå¿…é¡»æ˜ç¡®åˆ—å‡ºï¼šâ€œé’ˆå¯¹æ‚¨æåˆ°çš„[å…·ä½“éœ€æ±‚]ï¼Œæˆ‘ä¸ºæ‚¨åšäº†[å…·ä½“å®‰æ’]ã€‚â€
2.  **é‡æ„è¡Œç¨‹**ï¼šå¿…é¡»åŒ…å«ç”¨æˆ·åœ¨å¯¹è¯ä¸­è¦æ±‚å¢åŠ çš„æ™¯ç‚¹ã€‚
3.  **æ·±åº¦å†…å®¹**ï¼šæ™¯ç‚¹/éé—ä»‹ç»ä¸å°‘äº 150 å­—ï¼Œå¼ºè°ƒæ–‡åŒ–åº•è•´ã€‚

# Output Structure Template

# [ä¸ºä¸»æ ‡é¢˜èµ·ä¸€ä¸ªå¯Œæœ‰è¯—æ„çš„ä¸»é¢˜å]

## ğŸ“¢ è§„åˆ’å¸ˆæ·±åº¦å®šåˆ¶è¯´æ˜
> å°Šè´µçš„æ¸¸å®¢ï¼Œé’ˆå¯¹æ‚¨æåˆ°çš„ **[å…³é”®æŒ‡ä»¤è¯]**ï¼Œæˆ‘åšäº†å¦‚ä¸‹è°ƒæ•´ï¼š
> - âœ… **[å…·ä½“è°ƒæ•´åŠ¨ä½œ]**ï¼š[æè¿°è¡Œç¨‹å¦‚ä½•é‡ç»„]
> - ğŸŒ¤ï¸ **[å¤©æ°”é¢„è­¦é€‚é…]**ï¼š[æè¿°é’ˆå¯¹å¤©æ°”çš„èŠ‚å¥è°ƒæ•´]

## ğŸ’ è¡Œå‰é”¦å›Šä¸ç¯å¢ƒæ„ŸçŸ¥
- **æ°”è±¡è§£æ**ï¼š[åŸºäºå¤©æ°”æ•°æ®çš„å»ºè®®]
- **ç©¿è¡£æŒ‡æ•°**ï¼š[å…·ä½“åˆ°è¡£ç‰©ç±»å‹]
- **è¡Œå‰æœŸå¾…**ï¼š[ä¸€å¥è¯å‹¾èµ·æ–‡åŒ–å…´è¶£]

## ğŸ“œ æ¯æ—¥æ·±åº¦è·¯ä¹¦ (ç²¾æ„ç‰ˆ)

### ç¬¬[X]å¤©ï¼š[å¯Œæœ‰éŸµå¾‹çš„ä¸»é¢˜]
#### ğŸ“ [æ—¶é—´æ®µ] | [é¡¹ç›®åç§°]
- **æ–‡åŒ–åº•è•´**ï¼š[150å­—ä»¥ä¸Šæ·±åº¦è§£è¯»ï¼Œèåˆç´ æåº“å†…å®¹]
- **ğŸ‘€ ç»ä½³çœ‹ç‚¹**ï¼š[æè¿°ä¸å¯é”™è¿‡çš„ç»†èŠ‚]
- **ğŸ‘ åŒ å¿ƒä½“éªŒ**ï¼š[æè¿°äº’åŠ¨å‚ä¸å†…å®¹]
- **ğŸ² é™„è¿‘å¯»å‘³**ï¼š[æ¨èå½“åœ°ç‰¹è‰²éé—ç¾é£Ÿ]
- **ğŸ“¸ é•œå¤´æ•æ‰ï¼šæä¾›æ‘„å½±å»ºè®®ï¼Œæ¯”å¦‚é™„è¿‘å“ªäº›åœ°æ–¹å‡ºç‰‡ï¼Œæå‡æ—…è¡Œçš„ä»ªå¼æ„Ÿã€‚
- **ğŸ›ï¸ æ–‡åˆ›æ‹¾é—ï¼šå¼•å¯¼æ–‡åŒ–æ¶ˆè´¹ï¼Œæ¨èå€¼å¾—å¸¦èµ°çš„çºªå¿µå“ã€‚
- **ğŸ’¡ è§„åˆ’å¸ˆç§è—ï¼šæä¾›åªæœ‰èµ„æ·±ä¸“å®¶æ‰çŸ¥é“çš„â€œéšè—ç»†èŠ‚â€æˆ–â€œé¿å‘æŒ‡å—â€ã€‚

...
"""
            
            logger.info(f"å‘é€ AI è¯·æ±‚ã€‚åŸå§‹æ•°æ®é•¿åº¦: {len(str(actual_data))} -> ä¼˜åŒ–å Prompt é•¿åº¦: {len(prompt)}")
            
            response = await self.ali_model._call_model(prompt)
            if not response or not response.get('success'):
                return self._create_fallback_content(actual_data)
            
            return {
                'content_type': 'rich_text',
                'text_content': response.get('content', '').strip(),
                'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'ai_generated': True,
                'source_data': {'destination': destination, 'travel_dates': travel_dates}
            }
                
        except Exception as e:
            logger.error(f"AIè‡ªä¸»å†…å®¹æ•´åˆå¤±è´¥: {str(e)}")
            return self._create_fallback_content(result.get('plan_data', result))
    
    async def _build_conversation_summary(self, conversation_history: List[Dict] = None, actual_data: Dict = None) -> str:
        """
        æ„å»ºå¯¹è¯å†å²æ‘˜è¦ï¼ˆåŸºäº LLM æ™ºèƒ½æ‘˜è¦ï¼‰
        
        Args:
            conversation_history: å¯¹è¯å†å²åˆ—è¡¨
            actual_data: å®é™…æ•°æ®
        
        Returns:
            str: å¯¹è¯å†å²æ‘˜è¦
        """
        if not conversation_history and actual_data:
            conversation_history = self._extract_conversation_history_list(actual_data)
        
        if not conversation_history:
            return "æš‚æ— ç‰¹æ®Šè¦æ±‚ã€‚"
        
        try:
            # å°†å¯¹è¯å†å²è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
            conversation_text = self._format_conversation_to_text(conversation_history)
            
            logger.info(f"å¼€å§‹å¯¹ {len(conversation_history)} æ¡å¯¹è¯å†å²è¿›è¡Œæ™ºèƒ½æ‘˜è¦...")
            
            # ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ‘˜è¦
            summary_prompt = CONVERSATION_SUMMARY_PROMPT.format(
                conversation_history=conversation_text
            )
            
            # è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
            response = await self.ali_model._call_model(summary_prompt)
            
            if response and response.get('success'):
                summary = response.get('content', '').strip()
                logger.info(f"å¯¹è¯å†å²æ‘˜è¦ç”Ÿæˆå®Œæˆï¼Œæ‘˜è¦é•¿åº¦: {len(summary)} å­—ç¬¦")
                return summary
            else:
                logger.warning("LLM æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                return self._build_conversation_summary_fallback(conversation_history)
                
        except Exception as e:
            logger.error(f"å¯¹è¯å†å²æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œé™çº§ä¸ºç®€å•æˆªå–: {str(e)}")
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç®€å•æˆªå–
            return self._build_conversation_summary_fallback(conversation_history)
    
    def _format_conversation_to_text(self, conversation_history: List[Dict]) -> str:
        """
        å°†å¯¹è¯å†å²è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
        
        Args:
            conversation_history: å¯¹è¯å†å²åˆ—è¡¨
        
        Returns:
            str: æ ¼å¼åŒ–çš„å¯¹è¯æ–‡æœ¬
        """
        lines = []
        for idx, msg in enumerate(conversation_history, 1):
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            
            if role == 'user':
                lines.append(f"{idx}. ç”¨æˆ·: {content}")
            elif role == 'assistant':
                lines.append(f"{idx}. åŠ©æ‰‹: {content}")
        
        return "\n".join(lines)
    
    def _build_conversation_summary_fallback(self, conversation_history: List[Dict]) -> str:
        """
        é™çº§æ–¹æ¡ˆï¼šæ„å»ºå¯¹è¯å†å²æ‘˜è¦ï¼ˆç®€å•æˆªå–ï¼‰
        
        Args:
            conversation_history: å¯¹è¯å†å²åˆ—è¡¨
        
        Returns:
            str: å¯¹è¯å†å²æ‘˜è¦
        """
        user_demands = []
        
        # èšç„¦æœ€è¿‘å‡ è½®å¯¹è¯ï¼Œè¿™æ˜¯ç”¨æˆ·ä¿®æ”¹æ„å›¾æœ€é›†ä¸­çš„åœ°æ–¹
        for msg in conversation_history[-8:]:
            role = "ç”¨æˆ·" if msg.get('role') == 'user' else "åŠ©æ‰‹"
            content = msg.get('content', '')[:200]
            user_demands.append(f"{role}: {content}")
        
        return "\n".join(user_demands) if user_demands else "æš‚æ— ç‰¹æ®Šè¦æ±‚ã€‚"
    
    def _create_fallback_content(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨å†…å®¹"""
        dest = self.content_extractor.extract_destination(result)
        return {
            'content_type': 'rich_text',
            'text_content': f"# {dest} éé—æ–‡åŒ–ä¹‹æ—…\n\næŠ±æ­‰ï¼Œæ·±åº¦å†…å®¹ç”Ÿæˆç¹å¿™ï¼Œè¯·å‚è€ƒåŸºç¡€è¡Œç¨‹å•ã€‚\n\n## åŸºç¡€ä¿¡æ¯\nç›®çš„åœ°ï¼š{dest}",
            'ai_generated': False,
            'fallback': True
        }